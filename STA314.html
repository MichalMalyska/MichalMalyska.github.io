<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Michal Malyska" />


<title>STA314 Materials</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Michal Malyska</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-university"></span>
     
    Teaching
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="STA303.html">
        <span class="fa fa-book"></span>
         
        STA303 - Methods of Data Analysis II
      </a>
    </li>
    <li>
      <a href="STA314.html">
        <span class="fa fa-book"></span>
         
        STA314 - Machine Learning I
      </a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-book"></span>
     
    Course Work
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="STA490_Project1.html">
        <span class="fa fa-code"></span>
         
        STA490 - Stats Consulting and Collaboration
      </a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-pencil"></span>
     
    Personal Projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="OSFI.html">
        <span class="fa fa-code"></span>
         
        OSFI P &amp; C data extraction
      </a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">
    <span class="fa fa-info"></span>
     
    About me
  </a>
</li>
<li>
  <a href="resume.pdf">
    <span class="fa fa-file-pdf-o"></span>
     
    Resume
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">STA314 Materials</h1>
<h4 class="author"><em>Michal Malyska</em></h4>

</div>


<div id="preamble" class="section level1">
<h1>Preamble</h1>
<div id="most-of-the-work-in-this-file-is-the-edited-version-of-solutions-provided-by-prof.daniel-simpson-who-is-the-instructor-for-this-course." class="section level3">
<h3>Most of the work in this file is the edited version of solutions provided by Prof. Daniel Simpson who is the instructor for this course.</h3>
</div>
<div id="resources" class="section level2">
<h2>Resources</h2>
<p><a href="http://r4ds.had.co.nz/">Learn R with tidyverse</a> - this on it’s own should give you good enough background to handle most of the coding</p>
<p><a href="https://adv-r.hadley.nz/">Advanced R with tidyverse</a> - most likely far beyond the scope of what’s needed for the course</p>
</div>
<div id="library-load" class="section level2">
<h2>Library Load</h2>
<pre class="r"><code>library(tidyverse)
library(gridExtra)
library(MASS)
library(ISLR)
library(car)
library(modelr)
library(gapminder)
library(broom)</code></pre>
</div>
</div>
<div id="week-1" class="section level1">
<h1>Week 1</h1>
</div>
<div id="week-2" class="section level1">
<h1>Week 2</h1>
<div id="question-2" class="section level2">
<h2>Question 2</h2>
<pre class="r"><code>my_kmeans &lt;- function(data, k, n_starts) {
    
done = FALSE # Initialize the condition vector
n = dim(data)[1] #data is a matrix, where each row is one data point

if (k == 1) {
    cluster = rep(1, n) #this vector says which cluster each point is in
    
    centers = apply(
        X = data,
        MARGIN = 2,
        FUN = mean
        ) # Calculate the average distance
    
    cost = sum((data - centers[cluster]) ^ 2) # Compute the cost function for the single cluster
    
    return(list(cluster = cluster, cost = cost)) # Returns a list of [cluster, cost]
}

cluster_old = rep(1, n) # initialize clusters
cost_old = Inf # initialize cost

for (run in 1:n_starts) {
    cluster = rep(1, n) #this vector says which cluster each point is in
    #uniformly choose initial cluster centers
    centers = data[sample(
        x = 1:n,
        size = k,
        replace = FALSE)
    , ] # Sampling datapoints to be cluster centers
    
    while (!done) {
        # Do Step 2.1
        d = matrix(nrow = n, ncol = k) #initialize a matrix of size nxk
        for (j in 1:k) {
            d[, j] = apply(
            X = data,
            MARGIN = 1, #MARGIN = 1 =&gt; Rowwise
            FUN = function(d) sum((d - centers[j, ]) ^ 2)
        ) # Computes the cost function for each point for each cluster center
            
        }
        cluster_new = apply(
            X = d,
            MARGIN = 1,
            FUN = which.min
            ) # Take the minimum of the costs
        
# Throw an error if there is a cluster with no points in it
if (length(unique(cluster_new)) &lt; k) stop(&quot;Empty cluster!&quot;) 

        
# Do Step 2.2
        for (i in 1:k) {
            centers[i, ] = apply(
                X = data[cluster_new == i, ],
                MARGIN = 2, #MARGIN = 2 =&gt; Columnwise
                FUN = mean) # Computes mean of the cluster for each cluster
        }
        
# Check if the cluster assignements changed. If they have, set done=TRUE
        if (all(cluster == cluster_new)) {
            done = TRUE
        }
        
        # Update step 
        cluster = cluster_new
    } #end of while not done
    
cost = sum((data - centers[cluster, ]) ^ 2) # Compute the cost

if (cost_old &lt; cost) {
    cluster = cluster_old
    cost = cost_old
    }
    
    cost_old = cost
    cluster_old = cluster
} # if the cost increased, undo

return(list(cluster = cluster, cost = cost))
}</code></pre>
<div id="task-use-this-algorithm-to-make-a-4-clustering-of-the-data-set-in-question2.rdata.-comment-on-the-clustering." class="section level3">
<h3>Task : Use this algorithm to make a 4 clustering of the data set in question2.RData. Comment on the clustering.</h3>
<pre class="r"><code># Load the data from a data file 
load(&quot;~/Desktop/University/Statistics/TA-ing/STA314/T2/question2.RData&quot;)

# Load the data from a csv file
#data_q2 &lt;- read_csv(&quot;Question2_data.csv&quot;)


out = my_kmeans(dat_q2 #data 
                , 4 # number of clusters
                , 2 # number of runs
                )

dat_q2$cluster = out$cluster # Assign to the column &quot;cluster&quot; in dat_q2 the column &quot;cluster&quot; in out

dat_q2 %&gt;% ggplot(aes(x = x,y = y)) +
    geom_point(aes(colour = factor(cluster))) #plot</code></pre>
<p><img src="STA314_files/figure-html/Q2%20continued-1.png" width="672" /></p>
<p>Depending on how many times the kmeans algorithm is run, it sometimes doesn’t find all four distinct clusters. This is due to the uniform intial sampling and the fact that the bottom left and top right clusters are much smaller than the other two. Try increasing the number of runs!</p>
</div>
</div>
<div id="question-3" class="section level2">
<h2>Question 3</h2>
<pre class="r"><code># Input the data
d = matrix(c(0, 0.3, 0.4, 0.7,
0.3, 0, 0.5, 0.8,
0.4, 0.5, 0.0, 0.45,
0.7, 0.8, 0.45, 0.0), nrow = 4)


# Set it as distance
d = as.dist(d)</code></pre>
<pre class="r"><code># Plot the clusters with complete linkage:
plot(hclust(d,method = &quot;complete&quot;))</code></pre>
<p><img src="STA314_files/figure-html/Q3%20Complete%20Linkage-1.png" width="672" /></p>
<pre class="r"><code># Plot the clusters with complete linkage:
plot(hclust(d,method = &quot;single&quot;))</code></pre>
<p><img src="STA314_files/figure-html/Q3%20Single%20Linkage-1.png" width="672" /></p>
<pre class="r"><code>plot(hclust(d,method = &quot;average&quot;))</code></pre>
<p><img src="STA314_files/figure-html/Q3%20Average%20Linkage-1.png" width="672" /></p>
<p>Comparing the two dendrograms, we see that the two clustering from the complete linkage is {1,2}, {3,4}, while the two clustering from the single linkage is {1,2,3}, {4}.</p>
</div>
<div id="question-4" class="section level2">
<h2>Question 4</h2>
<p>For part a) there is not enough information. If the two linkages are equal, then they will fuse at the same hight. Otherwise, the single linkage dendrogram will merge at a lower hight as it only requires one nearby point and not all of the points to be close.</p>
<p>For part b) They’ll merge at the same hight because when you’re just merging single leaves, the linkages all reduce to the distance and are therefore equal.</p>
</div>
</div>
<div id="week-3" class="section level1">
<h1>Week 3</h1>
<div id="question-2-1" class="section level2">
<h2>Question 2</h2>
<p>Medium house value (medv) for 506 neighborhoods in Boston. Includes 13 predictors such as: Avg number of rooms in the house, Avg age of houses, socioeconomic status.</p>
<pre class="r"><code># Load the data: (from the MASS package)
data(Boston)

# Check names of variables:
names(Boston)</code></pre>
<pre><code>##  [1] &quot;crim&quot;    &quot;zn&quot;      &quot;indus&quot;   &quot;chas&quot;    &quot;nox&quot;     &quot;rm&quot;      &quot;age&quot;    
##  [8] &quot;dis&quot;     &quot;rad&quot;     &quot;tax&quot;     &quot;ptratio&quot; &quot;black&quot;   &quot;lstat&quot;   &quot;medv&quot;</code></pre>
<p>Let’s try fitting a linear model of medv ~ lstat (socioeconomic status)</p>
<pre class="r"><code># Results in an error - doesn&#39;t know where to get the data from.
# lm_fit &lt;- lm(medv ~ lstat)

# Need to specify data = , this is good practice as opposed to following the 
# order set by R inside of the functions most of the time.
lm_fit &lt;- lm(data = Boston, formula = medv ~ lstat)</code></pre>
<p>Now let’s see what the result of the lm function looks like:</p>
<pre class="r"><code># Basic information:
lm_fit</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ lstat, data = Boston)
## 
## Coefficients:
## (Intercept)        lstat  
##       34.55        -0.95</code></pre>
<pre class="r"><code># More comprehensive:
summary(lm_fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ lstat, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.168  -3.990  -1.318   2.034  24.500 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***
## lstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.216 on 504 degrees of freedom
## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 
## F-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># What are the contents of lm?
names(lm_fit)</code></pre>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;</code></pre>
<pre class="r"><code># Extracting p-values:

## Save the summary(lm) as an object! 
sum_lm &lt;- summary(lm_fit)

## P-values are stored with coefficients in the fourth column:
### Intercept P-value:
sum_lm$coefficients[,4][1]</code></pre>
<pre><code>##   (Intercept) 
## 3.743081e-236</code></pre>
<pre class="r"><code>### lstat P-value:
sum_lm$coefficients[,4][2]</code></pre>
<pre><code>##        lstat 
## 5.081103e-88</code></pre>
<pre class="r"><code># Or you can just call it directly:
summary(lm_fit)$coefficients[,4][1]</code></pre>
<pre><code>##   (Intercept) 
## 3.743081e-236</code></pre>
<pre class="r"><code># Cleanup:
rm(sum_lm)</code></pre>
<p>Now how about predicting and plotting the data:</p>
<pre class="r"><code># Find the intervals for new data

# Confidence intervals:
predict(lm_fit, data.frame(lstat = c(5, 10, 15)),
        interval = &#39;confidence&#39;)</code></pre>
<pre><code>##        fit      lwr      upr
## 1 29.80359 29.00741 30.59978
## 2 25.05335 24.47413 25.63256
## 3 20.30310 19.73159 20.87461</code></pre>
<pre class="r"><code># Prediction interals: 
predict(lm_fit, data.frame(lstat = c(5, 10, 15)),
        interval = &#39;prediction&#39;)</code></pre>
<pre><code>##        fit       lwr      upr
## 1 29.80359 17.565675 42.04151
## 2 25.05335 12.827626 37.27907
## 3 20.30310  8.077742 32.52846</code></pre>
<pre class="r"><code># Plotting:
plot(Boston$lstat, Boston$medv)
abline(lm_fit)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-1.png" width="672" /></p>
<pre class="r"><code># Playing around with base graphics
plot(Boston$lstat, Boston$medv)
abline(lm_fit ,lwd = 3)
abline(lm_fit ,lwd = 3,col = &quot;red&quot;)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-2.png" width="672" /></p>
<pre class="r"><code>plot(Boston$lstat ,Boston$medv ,col = &quot;red&quot;)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-3.png" width="672" /></p>
<pre class="r"><code>plot(Boston$lstat ,Boston$medv ,pch = 20)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-4.png" width="672" /></p>
<pre class="r"><code>plot(Boston$lstat ,Boston$medv ,pch = &quot;+&quot;)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-5.png" width="672" /></p>
<pre class="r"><code># Some available symbols:
plot(1:20, 1:20, pch = 1:20)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-6.png" width="672" /></p>
<pre class="r"><code># Plotting multiple plots on the same line
par(mfrow = c(2,2))

# plot diagnostics
plot(lm_fit)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-7.png" width="672" /></p>
<pre class="r"><code># revert back to 1 plot per plot
par(mfrow = c(1,1))

plot(predict(lm_fit), residuals(lm_fit))</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-8.png" width="672" /></p>
<pre class="r"><code>plot(predict(lm_fit), rstudent(lm_fit)) # standardized residuals</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-9.png" width="672" /></p>
<pre class="r"><code># We observe non-linearity - compute the leverage stats and see which one has the largest
plot(hatvalues(lm_fit))</code></pre>
<p><img src="STA314_files/figure-html/Question%202.4%20-%20predicting%20and%20plotting%20(base)-10.png" width="672" /></p>
<pre class="r"><code># Which observation has the highest leverage:
which.max(hatvalues(lm_fit))</code></pre>
<pre><code>## 375 
## 375</code></pre>
<pre class="r"><code># Or plotting using ggplot:
p &lt;- ggplot(data = Boston, aes(x = lstat, y = medv))
p &lt;- p + geom_point()
p &lt;- p + geom_smooth(method = &quot;lm&quot;, colour = &quot;red&quot;)
p &lt;- p + theme_bw()
p</code></pre>
<p><img src="STA314_files/figure-html/Question%202.5%20-%20plotting%20using%20ggplot-1.png" width="672" /></p>
<pre class="r"><code># We can add age to our model (without the interaction)
lm_fit2 &lt;- lm(medv ~ lstat + age, data = Boston)
summary(lm_fit2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ lstat + age, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.981  -3.978  -1.283   1.968  23.158 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***
## lstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***
## age          0.03454    0.01223   2.826  0.00491 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.173 on 503 degrees of freedom
## Multiple R-squared:  0.5513, Adjusted R-squared:  0.5495 
## F-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># We can use all the variables available:
lm_fit3 &lt;- lm(medv ~ ., data = Boston)
summary(lm_fit3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.595  -2.730  -0.518   1.777  26.199 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
## crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** 
## zn           4.642e-02  1.373e-02   3.382 0.000778 ***
## indus        2.056e-02  6.150e-02   0.334 0.738288    
## chas         2.687e+00  8.616e-01   3.118 0.001925 ** 
## nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
## rm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***
## age          6.922e-04  1.321e-02   0.052 0.958229    
## dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
## rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***
## tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** 
## ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
## black        9.312e-03  2.686e-03   3.467 0.000573 ***
## lstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.745 on 492 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 
## F-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># We can use all the variables but one:
lm_fit4 &lt;- lm(medv ~ . -age, data = Boston)
summary(lm_fit4)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ . - age, data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.6054  -2.7313  -0.5188   1.7601  26.2243 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  36.436927   5.080119   7.172 2.72e-12 ***
## crim         -0.108006   0.032832  -3.290 0.001075 ** 
## zn            0.046334   0.013613   3.404 0.000719 ***
## indus         0.020562   0.061433   0.335 0.737989    
## chas          2.689026   0.859598   3.128 0.001863 ** 
## nox         -17.713540   3.679308  -4.814 1.97e-06 ***
## rm            3.814394   0.408480   9.338  &lt; 2e-16 ***
## dis          -1.478612   0.190611  -7.757 5.03e-14 ***
## rad           0.305786   0.066089   4.627 4.75e-06 ***
## tax          -0.012329   0.003755  -3.283 0.001099 ** 
## ptratio      -0.952211   0.130294  -7.308 1.10e-12 ***
## black         0.009321   0.002678   3.481 0.000544 ***
## lstat        -0.523852   0.047625 -10.999  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.74 on 493 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7343 
## F-statistic: 117.3 on 12 and 493 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># Can also update the previous model variables to exclude age:
update(lm_fit3, ~ . -age)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ crim + zn + indus + chas + nox + rm + dis + 
##     rad + tax + ptratio + black + lstat, data = Boston)
## 
## Coefficients:
## (Intercept)         crim           zn        indus         chas  
##   36.436927    -0.108006     0.046334     0.020562     2.689026  
##         nox           rm          dis          rad          tax  
##  -17.713540     3.814394    -1.478612     0.305786    -0.012329  
##     ptratio        black        lstat  
##   -0.952211     0.009321    -0.523852</code></pre>
<pre class="r"><code>summary(lm_fit3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.595  -2.730  -0.518   1.777  26.199 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***
## crim        -1.080e-01  3.286e-02  -3.287 0.001087 ** 
## zn           4.642e-02  1.373e-02   3.382 0.000778 ***
## indus        2.056e-02  6.150e-02   0.334 0.738288    
## chas         2.687e+00  8.616e-01   3.118 0.001925 ** 
## nox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***
## rm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***
## age          6.922e-04  1.321e-02   0.052 0.958229    
## dis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***
## rad          3.060e-01  6.635e-02   4.613 5.07e-06 ***
## tax         -1.233e-02  3.760e-03  -3.280 0.001112 ** 
## ptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***
## black        9.312e-03  2.686e-03   3.467 0.000573 ***
## lstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.745 on 492 degrees of freedom
## Multiple R-squared:  0.7406, Adjusted R-squared:  0.7338 
## F-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>One big problem with multiple regression is Multicolinearity, to investigate if this is an issue with our models we will be using the car package.</p>
<pre class="r"><code># print Variance Inflation Factors: Common cutoffs are 10 or 5
vif(lm_fit3)</code></pre>
<pre><code>##     crim       zn    indus     chas      nox       rm      age      dis 
## 1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 
##      rad      tax  ptratio    black    lstat 
## 7.484496 9.008554 1.799084 1.348521 2.941491</code></pre>
<p>The interpretation of VIF is that if say VIF(tax) = ~9, then the standard error for the coefficient associated with tax is $  = 3 $ times as large as it would be if the variables were uncorrelated.</p>
<pre class="r"><code># If we want to include the interactions between variables we use the * symbol 
summary(lm(medv ~ lstat * age, data = Boston))</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ lstat * age, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.806  -4.045  -1.333   2.085  27.552 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 36.0885359  1.4698355  24.553  &lt; 2e-16 ***
## lstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***
## age         -0.0007209  0.0198792  -0.036   0.9711    
## lstat:age    0.0041560  0.0018518   2.244   0.0252 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.149 on 502 degrees of freedom
## Multiple R-squared:  0.5557, Adjusted R-squared:  0.5531 
## F-statistic: 209.3 on 3 and 502 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># it automatically includes the variables themselves in the call!

# We can also add non-linear transformations of predictors:
lm_fit_square &lt;- lm(medv ~ lstat + I(lstat^2), data = Boston)
summary(lm_fit_square)</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ lstat + I(lstat^2), data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -15.2834  -3.8313  -0.5295   2.3095  25.4148 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 42.862007   0.872084   49.15   &lt;2e-16 ***
## lstat       -2.332821   0.123803  -18.84   &lt;2e-16 ***
## I(lstat^2)   0.043547   0.003745   11.63   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.524 on 503 degrees of freedom
## Multiple R-squared:  0.6407, Adjusted R-squared:  0.6393 
## F-statistic: 448.5 on 2 and 503 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>plot(lm_fit_square)</code></pre>
<p><img src="STA314_files/figure-html/Question%202.8%20-%20Interactions-1.png" width="672" /><img src="STA314_files/figure-html/Question%202.8%20-%20Interactions-2.png" width="672" /><img src="STA314_files/figure-html/Question%202.8%20-%20Interactions-3.png" width="672" /><img src="STA314_files/figure-html/Question%202.8%20-%20Interactions-4.png" width="672" /></p>
<pre class="r"><code># Test if the model with a square is better than the simpler one:
anova(lm_fit, lm_fit_square)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: medv ~ lstat
## Model 2: medv ~ lstat + I(lstat^2)
##   Res.Df   RSS Df Sum of Sq     F    Pr(&gt;F)    
## 1    504 19472                                 
## 2    503 15347  1    4125.1 135.2 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># We can include higher polynomials:
summary(lm(medv ~ poly(lstat, 10), data = Boston))</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ poly(lstat, 10), data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.5340  -3.0286  -0.7507   2.0437  26.4738 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         22.5328     0.2311  97.488  &lt; 2e-16 ***
## poly(lstat, 10)1  -152.4595     5.1993 -29.323  &lt; 2e-16 ***
## poly(lstat, 10)2    64.2272     5.1993  12.353  &lt; 2e-16 ***
## poly(lstat, 10)3   -27.0511     5.1993  -5.203 2.88e-07 ***
## poly(lstat, 10)4    25.4517     5.1993   4.895 1.33e-06 ***
## poly(lstat, 10)5   -19.2524     5.1993  -3.703 0.000237 ***
## poly(lstat, 10)6     6.5088     5.1993   1.252 0.211211    
## poly(lstat, 10)7     1.9416     5.1993   0.373 0.708977    
## poly(lstat, 10)8    -6.7299     5.1993  -1.294 0.196133    
## poly(lstat, 10)9     8.4168     5.1993   1.619 0.106116    
## poly(lstat, 10)10   -7.3351     5.1993  -1.411 0.158930    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.199 on 495 degrees of freedom
## Multiple R-squared:  0.6867, Adjusted R-squared:  0.6804 
## F-statistic: 108.5 on 10 and 495 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># As we can see up to the 5th power all are statistically significant!

# We can also include different functions:
summary(lm(medv ~ log(lstat), data = Boston))</code></pre>
<pre><code>## 
## Call:
## lm(formula = medv ~ log(lstat), data = Boston)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -14.4599  -3.5006  -0.6686   2.1688  26.0129 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  52.1248     0.9652   54.00   &lt;2e-16 ***
## log(lstat)  -12.4810     0.3946  -31.63   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.329 on 504 degrees of freedom
## Multiple R-squared:  0.6649, Adjusted R-squared:  0.6643 
## F-statistic:  1000 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="r-for-data-science-chapter-25-many-models" class="section level2">
<h2>R for data science chapter 25: Many Models</h2>
<p>This is beyond the scope of what we teach, but you might find it very useful in practice:</p>
<pre class="r"><code># We will be using the modelr and gapminder libraries for this part
gapminder</code></pre>
<pre><code>## # A tibble: 1,704 x 6
##    country     continent  year lifeExp      pop gdpPercap
##    &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;
##  1 Afghanistan Asia       1952    28.8  8425333      779.
##  2 Afghanistan Asia       1957    30.3  9240934      821.
##  3 Afghanistan Asia       1962    32.0 10267083      853.
##  4 Afghanistan Asia       1967    34.0 11537966      836.
##  5 Afghanistan Asia       1972    36.1 13079460      740.
##  6 Afghanistan Asia       1977    38.4 14880372      786.
##  7 Afghanistan Asia       1982    39.9 12881816      978.
##  8 Afghanistan Asia       1987    40.8 13867957      852.
##  9 Afghanistan Asia       1992    41.7 16317921      649.
## 10 Afghanistan Asia       1997    41.8 22227415      635.
## # ... with 1,694 more rows</code></pre>
<pre class="r"><code># plot life expectancy over time by country
gapminder %&gt;% 
  ggplot(aes(x = year, y = lifeExp, group = country)) +
    geom_line(alpha = 1/3)</code></pre>
<p><img src="STA314_files/figure-html/CH25:%20First%20Plot-1.png" width="672" /></p>
<p>It’s really hard to see what is going on!</p>
<p>Solution: Do it by country and nest all of the results in a table</p>
<pre class="r"><code># Create a tibble that separates each country&#39;s data into a separate tibble:
by_country &lt;- gapminder %&gt;% 
  group_by(country, continent) %&gt;% 
  nest()</code></pre>
<pre><code>## Warning: package &#39;bindrcpp&#39; was built under R version 3.4.4</code></pre>
<pre class="r"><code># We group by country and continent since for a country continent is fixed and we 
# want to carry on another variable

# View the data:
by_country</code></pre>
<pre><code>## # A tibble: 142 x 3
##    country     continent data             
##    &lt;fct&gt;       &lt;fct&gt;     &lt;list&gt;           
##  1 Afghanistan Asia      &lt;tibble [12 × 4]&gt;
##  2 Albania     Europe    &lt;tibble [12 × 4]&gt;
##  3 Algeria     Africa    &lt;tibble [12 × 4]&gt;
##  4 Angola      Africa    &lt;tibble [12 × 4]&gt;
##  5 Argentina   Americas  &lt;tibble [12 × 4]&gt;
##  6 Australia   Oceania   &lt;tibble [12 × 4]&gt;
##  7 Austria     Europe    &lt;tibble [12 × 4]&gt;
##  8 Bahrain     Asia      &lt;tibble [12 × 4]&gt;
##  9 Bangladesh  Asia      &lt;tibble [12 × 4]&gt;
## 10 Belgium     Europe    &lt;tibble [12 × 4]&gt;
## # ... with 132 more rows</code></pre>
<p>In this dataset each row is the complete dataset for a country, instead of being just one of the observations.</p>
<p>Now we want to fit a separate model for each of those rows:</p>
<pre class="r"><code># First we define the function that creates a linear model:
country_model &lt;- function(df) {
  lm(lifeExp ~ year, data = df)
}

# Then we can abuse the purrr package to apply that function to each of 
# the elements of a list:
by_country &lt;- by_country %&gt;%
    mutate(model = map(data, country_model))

# Now the column &quot;model&quot; in the by_country tibble contains all of the linear models we just fit!
by_country</code></pre>
<pre><code>## # A tibble: 142 x 4
##    country     continent data              model   
##    &lt;fct&gt;       &lt;fct&gt;     &lt;list&gt;            &lt;list&gt;  
##  1 Afghanistan Asia      &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  2 Albania     Europe    &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  3 Algeria     Africa    &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  4 Angola      Africa    &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  5 Argentina   Americas  &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  6 Australia   Oceania   &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  7 Austria     Europe    &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  8 Bahrain     Asia      &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
##  9 Bangladesh  Asia      &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
## 10 Belgium     Europe    &lt;tibble [12 × 4]&gt; &lt;S3: lm&gt;
## # ... with 132 more rows</code></pre>
<p>Now we want to look at the residuals, acessing models stored within tibbles is a hassle, so we can unnest the models:</p>
<pre class="r"><code>by_country &lt;- by_country %&gt;% 
  mutate(
    resids = map2(data, model, add_residuals)
  )

# Let&#39;s unnest the residuals:
resids &lt;- unnest(by_country, resids)

# Plot the residuals:
resids %&gt;% 
  ggplot(aes(year, resid)) +
    geom_line(aes(group = country), alpha = 1 / 3) + 
    geom_smooth(se = FALSE)</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;</code></pre>
<p><img src="STA314_files/figure-html/CH25:%20Unnesting-1.png" width="672" /></p>
<pre class="r"><code># Let&#39;s see the residuals by continent:
resids %&gt;% 
  ggplot(aes(year, resid, group = country)) +
    geom_line(alpha = 1 / 3) + 
    facet_wrap(~continent)</code></pre>
<p><img src="STA314_files/figure-html/CH25:%20Unnesting-2.png" width="672" /></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
